import argparse
import sys
import json
import os
import uuid
from datetime import datetime
# Updated imports for new structure
from parsers.sql_parser import LineageParser
from exporters.neo4j import Neo4jClient
from config.settings import settings

# Helper function to get parser instance
def get_parser():
    return LineageParser()

# Helper function to get neo4j client
def get_neo4j_client():
    return Neo4jClient()

def main():
    parser = argparse.ArgumentParser(description="SQL Lineage Engine CLI")
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Command: parse-sql
    sql_parser_cmd = subparsers.add_parser("parse-sql", help="Parse SQL and extract lineage")
    group = sql_parser_cmd.add_mutually_exclusive_group(required=True)
    group.add_argument("--sql", help="SQL string to parse")
    group.add_argument("--file", help="Path to SQL file to parse")
    sql_parser_cmd.add_argument("--dialect", default="mysql", help="SQL dialect (default: mysql)")
    sql_parser_cmd.add_argument("--output", choices=["csv", "json", "neo4j"], default="neo4j", help="Output mode (default: neo4j)")
    sql_parser_cmd.add_argument("--output-file", help="Path to write output to (CSV or JSON)")
    sql_parser_cmd.add_argument("--no-clear", action="store_true", help="Do not clear existing lineage data before parsing (default: clear all data)")
    
    args = parser.parse_args()

    if args.command == "parse-sql":
        lineage_parser = get_parser()
        neo4j = get_neo4j_client()
        
        lineage_parser.dialect = args.dialect
        
        import csv
        
        # 自动生成版本号
        version_id = f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}"
        print(f"Lineage version: {version_id}", file=sys.stderr)
        
        # 清除现有数据（仅在 neo4j 模式且未指定 --no-clear 时）
        if args.output == "neo4j" and neo4j and not args.no_clear:
            print("Clearing existing lineage data...", file=sys.stderr)
            neo4j.clear_all_lineage_data()

        # Determine output stream
        output_stream = sys.stdout
        file_handle = None
        
        if args.output_file:
             try:
                 file_handle = open(args.output_file, 'w', encoding='utf-8', newline='')
                 output_stream = file_handle
             except Exception as e:
                 print(f"Error opening output file: {e}", file=sys.stderr)
                 return

        # Track if CSV header has been printed
        csv_header_printed = False
        csv_writer = csv.writer(output_stream)

        def process_sql_content(content, file_path=None):
            nonlocal csv_header_printed
            
            # For table lineage
            result = lineage_parser.parse(content, source_file=file_path)
            
            # For column lineage (with dependency_type and source_file)
            col_dependencies = lineage_parser.get_column_lineage(content, source_file=file_path)
            
            if args.output == "json":
                # Add column dependencies to the result for JSON output
                result["columnDependencies"] = col_dependencies
                # Print to output stream
                print(json.dumps(result, indent=2, ensure_ascii=False), file=output_stream)
            
            elif args.output == "csv":
                if not csv_header_printed:
                    csv_writer.writerow(["SourceTable", "SourceColumn", "TargetTable", "TargetColumn", "Type"])
                    csv_header_printed = True
                
                # Check for relationships key (new format)
                if "relationships" in result and result["relationships"]:
                    for rel in result["relationships"]:
                        csv_writer.writerow([
                            rel.get("source", ""),
                            "", # Source Column (not in table relations)
                            rel.get("target", ""),
                            "", # Target Column
                            rel.get("type", "")
                        ])
                else:
                    # Fallback to old cross-product logic if no relationships found (or old parser version)
                    # Table level (no column info)
                    if "sources" in result and "targets" in result:
                         for source in result["sources"]:
                            for target in result["targets"]:
                                 csv_writer.writerow([source, "", target, "", "fdd"])

                # Column level (with dependency_type)
                for dep in col_dependencies:
                     csv_writer.writerow([
                         dep.get("source_table", ""),
                         dep.get("source_column", ""),
                         dep.get("target_table", ""),
                         dep.get("target_column", ""),
                         dep.get("dependency_type", "fdd")  # 使用 dependency_type
                     ])
                     
            elif args.output == "neo4j":
                if neo4j:
                    inserted_any = False
                    
                    # Store relationships if available
                    if "relationships" in result and result["relationships"]:
                        for rel in result["relationships"]:
                            try:
                                neo4j.create_lineage(rel.get("source"), rel.get("target"))
                                inserted_any = True
                            except Exception as e:
                                print(f"Error storing table lineage: {e}", file=sys.stderr)
                    
                    # Fallback to old logic if no relationships found but sources/targets exist
                    if not inserted_any and "sources" in result and "targets" in result:
                        for source in result["sources"]:
                            for target in result["targets"]:
                                try:
                                    neo4j.create_lineage(source, target)
                                except Exception as e:
                                    print(f"Error storing table lineage: {e}", file=sys.stderr)
                    
                    # Batch insert column lineage with version
                    try:
                        neo4j.create_column_lineage_v2(col_dependencies, version=version_id)
                    except Exception as e:
                        print(f"Error storing column lineage: {e}", file=sys.stderr)

                else:
                    print("Neo4j client not initialized.", file=sys.stderr)

        try:
            # 创建版本节点 (仅在 neo4j 模式下)
            if args.output == "neo4j" and neo4j:
                source_dir = args.file if args.file and os.path.isdir(args.file) else (
                    os.path.dirname(args.file) if args.file else None
                )
                neo4j.create_lineage_version(
                    version_id=version_id,
                    source_directory=source_dir,
                    description=f"Parsed from {args.file or 'inline SQL'}"
                )
            
            if args.sql:
                process_sql_content(args.sql, file_path=None)
            elif args.file:
                if os.path.isdir(args.file):
                    # Directory mode - 使用多进程并行解析
                    from concurrent.futures import ThreadPoolExecutor, as_completed
                    from parsers.parallel_parser import parse_single_file, prepare_file_tasks
                    
                    sql_files = []
                    for root, dirs, files in os.walk(args.file):
                        for file in files:
                            if file.lower().endswith(".sql"):
                                sql_files.append(os.path.join(root, file))
                    
                    total_files = len(sql_files)
                    print(f"Found {total_files} SQL files to process", file=sys.stderr)
                    
                    if total_files == 0:
                        print("No SQL files found.", file=sys.stderr)
                    else:
                        # 准备任务参数
                        tasks = prepare_file_tasks(sql_files, args.dialect)
                        
                        # 确定进程数
                        env_workers = os.environ.get("LINEAGE_MAX_WORKERS")
                        if env_workers and env_workers.isdigit():
                            max_workers = int(env_workers)
                        else:
                            max_workers = min(os.cpu_count() or 4, total_files)
                        print(f"Using {max_workers} worker processes", file=sys.stderr)
                        
                        # 收集所有结果
                        all_relationships = []
                        all_column_deps = []
                        success_count = 0
                        error_count = 0
                        
                        import time
                        if max_workers == 1:
                            print(f'[DEBUG] Running in SERIAL mode (bypassed) at {time.strftime("%H:%M:%S")}', file=sys.stderr)
                            for idx, task in enumerate(tasks, 1):
                                try:
                                    start_time = time.time()
                                    print(f"[DEBUG] Processing: {os.path.basename(task[0])}", file=sys.stderr)
                                    result = parse_single_file(task)
                                    duration = time.time() - start_time
                                    print(f"[{idx}/{total_files}] Completed: {os.path.basename(task[0])} in {duration:.2f}s", file=sys.stderr)
                                    if result["success"]:
                                        success_count += 1
                                        all_relationships.extend(result.get("relationships", []))
                                        all_column_deps.extend(result.get("column_dependencies", []))
                                    else:
                                        error_count += 1
                                        print(f"  Error: {result.get('error')}", file=sys.stderr)
                                except Exception as e:
                                    error_count += 1
                                    print(f"  Exception: {e}", file=sys.stderr)
                        else:
                            print(f"[DEBUG] Running in THREADED mode with {max_workers} workers", file=sys.stderr)
                            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                                # 提交所有任务
                                future_to_file = {executor.submit(parse_single_file, task): task[0] for task in tasks}
                                
                                # 处理完成的任务
                                for idx, future in enumerate(as_completed(future_to_file), 1):
                                    file_path = future_to_file[future]
                                    print(f"[{idx}/{total_files}] Completed: {os.path.basename(file_path)}", file=sys.stderr)
                                    
                                    try:
                                        result = future.result()
                                        if result["success"]:
                                            success_count += 1
                                            all_relationships.extend(result.get("relationships", []))
                                            all_column_deps.extend(result.get("column_dependencies", []))
                                        else:
                                            error_count += 1
                                            print(f"  Error: {result['error']}", file=sys.stderr)
                                    except Exception as e:
                                        error_count += 1
                                        print(f"  Exception: {e}", file=sys.stderr)
                            
                        print(f"Parsing complete: {success_count} succeeded, {error_count} failed", file=sys.stderr)
                        
                        # 批量写入结果
                        if args.output == "neo4j" and neo4j:
                            print(f"Writing {len(all_relationships)} table relationships to Neo4j (Batch)...", file=sys.stderr)
                            try:
                                neo4j.create_lineage_batch(all_relationships)
                            except Exception as e:
                                print(f"Error storing table lineage batch: {e}", file=sys.stderr)
                            
                            print(f"Writing {len(all_column_deps)} column dependencies to Neo4j...", file=sys.stderr)
                            try:
                                neo4j.create_column_lineage_v2(all_column_deps, version=version_id)
                            except Exception as e:
                                print(f"Error storing column lineage: {e}", file=sys.stderr)
                        
                        elif args.output == "json":
                            combined_result = {
                                "relationships": all_relationships,
                                "columnDependencies": all_column_deps
                            }
                            print(json.dumps(combined_result, indent=2, ensure_ascii=False), file=output_stream)
                        
                        elif args.output == "csv":
                            if not csv_header_printed:
                                csv_writer.writerow(["SourceTable", "SourceColumn", "TargetTable", "TargetColumn", "Type"])
                                csv_header_printed = True
                            for rel in all_relationships:
                                csv_writer.writerow([rel.get("source", ""), "", rel.get("target", ""), "", rel.get("type", "")])
                            for dep in all_column_deps:
                                csv_writer.writerow([
                                    dep.get("source_table", ""),
                                    dep.get("source_column", ""),
                                    dep.get("target_table", ""),
                                    dep.get("target_column", ""),
                                    dep.get("dependency_type", "fdd")
                                ])
                else:
                    # Single file mode
                    try:
                        with open(args.file, 'r', encoding='utf-8') as f:
                            sql_content = f.read()
                        process_sql_content(sql_content, file_path=args.file)
                    except Exception as e:
                        print(f"Error reading SQL file: {e}", file=sys.stderr)
        finally:
            if file_handle:
                file_handle.close()
            
            # 打印版本信息
            if args.output == "neo4j":
                print(f"Lineage stored with version: {version_id}", file=sys.stderr)


    else:
        parser.print_help()

if __name__ == "__main__":
    main()

