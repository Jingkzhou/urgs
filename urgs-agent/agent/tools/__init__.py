# CrewAI å·¥å…·å®šä¹‰
# URGS ç³»ç»Ÿå·¥å…·å±‚

from typing import Optional
import httpx
from crewai.tools import tool
from core.config import get_settings
from core.logging import get_logger

logger = get_logger("tools")


# ==================== RAG çŸ¥è¯†æ£€ç´¢å·¥å…· ====================


@tool("RAGçŸ¥è¯†æ£€ç´¢")
def query_knowledge(question: str) -> str:
    """
    ä» URGS çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

    Args:
        question: ç”¨æˆ·çš„é—®é¢˜æˆ–æŸ¥è¯¢å…³é”®è¯

    Returns:
        æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†å†…å®¹
    """
    settings = get_settings()
    rag_url = getattr(settings, "rag_service_url", "http://localhost:8001")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                f"{rag_url}/api/rag/query", json={"question": question}
            )
            response.raise_for_status()
            result = response.json()
            return result.get("answer", "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
    except httpx.HTTPError as e:
        logger.warning("rag_query_failed", error=str(e))
        return f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}"


@tool("æ–‡æ¡£æ‘˜è¦æ£€ç´¢")
def search_documents(keywords: str, top_k: int = 5) -> str:
    """
    æ ¹æ®å…³é”®è¯æœç´¢ç›¸å…³æ–‡æ¡£ã€‚

    Args:
        keywords: æœç´¢å…³é”®è¯
        top_k: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5æ¡

    Returns:
        åŒ¹é…çš„æ–‡æ¡£åˆ—è¡¨æ‘˜è¦
    """
    settings = get_settings()
    rag_url = getattr(settings, "rag_service_url", "http://localhost:8001")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                f"{rag_url}/api/rag/search", json={"keywords": keywords, "top_k": top_k}
            )
            response.raise_for_status()
            result = response.json()
            docs = result.get("documents", [])
            if not docs:
                return "æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£"
            return "\n".join(
                [
                    f"- {doc.get('title', 'æ— æ ‡é¢˜')}: {doc.get('summary', '')}"
                    for doc in docs
                ]
            )
    except httpx.HTTPError as e:
        logger.warning("doc_search_failed", error=str(e))
        return f"æ–‡æ¡£æœç´¢å¤±è´¥: {str(e)}"


# ==================== SQL è¡€ç¼˜åˆ†æå·¥å…· ====================


@tool("SQLè¡€ç¼˜åˆ†æ")
def analyze_sql_lineage(sql: str, dialect: str = "mysql") -> str:
    """
    è§£æ SQL è¯­å¥ï¼Œåˆ†æè¡¨å’Œå­—æ®µçº§åˆ«çš„è¡€ç¼˜å…³ç³»ã€‚

    Args:
        sql: è¦åˆ†æçš„ SQL è¯­å¥
        dialect: SQL æ–¹è¨€ï¼Œæ”¯æŒ mysql, postgresql, hive ç­‰

    Returns:
        è¡€ç¼˜åˆ†æç»“æœï¼ŒåŒ…å«æºè¡¨ã€ç›®æ ‡è¡¨ã€å­—æ®µæ˜ å°„
    """
    settings = get_settings()
    lineage_url = getattr(settings, "lineage_service_url", "http://localhost:8002")

    try:
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                f"{lineage_url}/api/lineage/parse",
                json={"sql": sql, "dialect": dialect},
            )
            response.raise_for_status()
            result = response.json()

            # æ ¼å¼åŒ–è¡€ç¼˜ç»“æœ
            lineage = result.get("lineage", {})
            sources = lineage.get("sources", [])
            targets = lineage.get("targets", [])

            output = []
            output.append(f"**æºè¡¨**: {', '.join(sources) if sources else 'æ— '}")
            output.append(f"**ç›®æ ‡è¡¨**: {', '.join(targets) if targets else 'æ— '}")

            if "columns" in lineage:
                output.append("\n**å­—æ®µè¡€ç¼˜**:")
                for col in lineage["columns"]:
                    output.append(
                        f"  - {col.get('source', '?')} â†’ {col.get('target', '?')}"
                    )

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("lineage_analysis_failed", error=str(e))
        return f"è¡€ç¼˜åˆ†æå¤±è´¥: {str(e)}"


@tool("æŸ¥è¯¢è¡¨è¡€ç¼˜å…³ç³»")
def query_table_lineage(table_name: str, direction: str = "both") -> str:
    """
    æŸ¥è¯¢æŒ‡å®šè¡¨çš„è¡€ç¼˜å…³ç³»ï¼ˆä¸Šä¸‹æ¸¸ï¼‰ã€‚

    Args:
        table_name: è¡¨å
        direction: æŸ¥è¯¢æ–¹å‘ï¼Œupstream(ä¸Šæ¸¸)ã€downstream(ä¸‹æ¸¸)ã€both(åŒå‘)

    Returns:
        è¡¨çš„è¡€ç¼˜å…³ç³»å›¾
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(
                f"{api_url}/api/lineage/table/{table_name}",
                params={"direction": direction},
            )
            response.raise_for_status()
            result = response.json()

            upstream = result.get("upstream", [])
            downstream = result.get("downstream", [])

            output = [f"**è¡¨ {table_name} çš„è¡€ç¼˜å…³ç³»**"]
            if upstream:
                output.append(f"\nä¸Šæ¸¸è¡¨: {', '.join(upstream)}")
            if downstream:
                output.append(f"\nä¸‹æ¸¸è¡¨: {', '.join(downstream)}")
            if not upstream and not downstream:
                output.append("\næœªå‘ç°è¡€ç¼˜å…³ç³»")

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("table_lineage_query_failed", error=str(e))
        return f"è¡€ç¼˜æŸ¥è¯¢å¤±è´¥: {str(e)}"


# ==================== ä»»åŠ¡æ‰§è¡Œå·¥å…· ====================


@tool("æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨")
def list_jobs(status: Optional[str] = None, limit: int = 10) -> str:
    """
    æŸ¥è¯¢è°ƒåº¦ä»»åŠ¡åˆ—è¡¨ã€‚

    Args:
        status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼Œå¯é€‰å€¼ï¼šrunning, success, failed, pending
        limit: è¿”å›æ•°é‡é™åˆ¶

    Returns:
        ä»»åŠ¡åˆ—è¡¨ä¿¡æ¯
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        params = {"limit": limit}
        if status:
            params["status"] = status

        with httpx.Client(timeout=30.0) as client:
            response = client.get(f"{api_url}/api/jobs", params=params)
            response.raise_for_status()
            result = response.json()

            jobs = result.get("data", [])
            if not jobs:
                return "å½“å‰æ²¡æœ‰ä»»åŠ¡"

            output = ["**è°ƒåº¦ä»»åŠ¡åˆ—è¡¨**\n"]
            for job in jobs[:limit]:
                status_icon = {
                    "running": "ğŸ”„",
                    "success": "âœ…",
                    "failed": "âŒ",
                    "pending": "â³",
                }.get(job.get("status", ""), "â“")
                output.append(
                    f"{status_icon} [{job.get('id')}] {job.get('name', 'æœªå‘½å')} - {job.get('status', 'æœªçŸ¥')}"
                )

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("list_jobs_failed", error=str(e))
        return f"æŸ¥è¯¢ä»»åŠ¡å¤±è´¥: {str(e)}"


@tool("æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…")
def get_job_detail(job_id: str) -> str:
    """
    è·å–æŒ‡å®šä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ã€‚

    Args:
        job_id: ä»»åŠ¡ ID

    Returns:
        ä»»åŠ¡è¯¦æƒ…ï¼ŒåŒ…å«é…ç½®ã€æ‰§è¡Œå†å²ç­‰
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(f"{api_url}/api/jobs/{job_id}")
            response.raise_for_status()
            job = response.json().get("data", {})

            output = [
                f"**ä»»åŠ¡è¯¦æƒ…: {job.get('name', job_id)}**\n",
                f"- ID: {job.get('id')}",
                f"- çŠ¶æ€: {job.get('status')}",
                f"- ç±»å‹: {job.get('type', 'æœªçŸ¥')}",
                f"- Cron: {job.get('cron', 'æ— ')}",
                f"- æœ€åæ‰§è¡Œ: {job.get('lastRunTime', 'ä»æœªæ‰§è¡Œ')}",
            ]

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("get_job_detail_failed", error=str(e))
        return f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}"


@tool("è§¦å‘ä»»åŠ¡æ‰§è¡Œ")
def trigger_job(job_id: str, params: Optional[str] = None) -> str:
    """
    è§¦å‘æŒ‡å®šä»»åŠ¡æ‰§è¡Œã€‚æ­¤æ“ä½œéœ€è¦å®¡æ‰¹ç¡®è®¤ã€‚

    Args:
        job_id: è¦æ‰§è¡Œçš„ä»»åŠ¡ ID
        params: å¯é€‰çš„æ‰§è¡Œå‚æ•° (JSON æ ¼å¼)

    Returns:
        æ‰§è¡Œè§¦å‘ç»“æœ

    æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªå†™æ“ä½œï¼Œç³»ç»Ÿå¯èƒ½ä¼šè¦æ±‚å®¡æ‰¹ç¡®è®¤ã€‚
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        import json

        body = {"jobId": job_id}
        if params:
            try:
                body["params"] = json.loads(params)
            except json.JSONDecodeError:
                body["params"] = params

        with httpx.Client(timeout=30.0) as client:
            response = client.post(f"{api_url}/api/jobs/{job_id}/trigger", json=body)
            response.raise_for_status()
            result = response.json()

            return f"âœ… ä»»åŠ¡ {job_id} å·²è§¦å‘æ‰§è¡Œï¼Œæ‰§è¡ŒID: {result.get('executionId', 'æœªçŸ¥')}"
    except httpx.HTTPError as e:
        logger.warning("trigger_job_failed", error=str(e))
        return f"è§¦å‘ä»»åŠ¡å¤±è´¥: {str(e)}"


# ==================== å·¥å…·é›†åˆ ====================


def get_rag_tools() -> list:
    """è·å– RAG ç›¸å…³å·¥å…·"""
    return [query_knowledge, search_documents]


def get_lineage_tools() -> list:
    """è·å–è¡€ç¼˜åˆ†æç›¸å…³å·¥å…·"""
    return [analyze_sql_lineage, query_table_lineage]


def get_executor_tools() -> list:
    """è·å–ä»»åŠ¡æ‰§è¡Œç›¸å…³å·¥å…·"""
    return [list_jobs, get_job_detail, trigger_job]


def get_all_tools() -> list:
    """è·å–æ‰€æœ‰å·¥å…·"""
    return get_rag_tools() + get_lineage_tools() + get_executor_tools()
