# CrewAI å·¥å…·å®šä¹‰
# URGS ç³»ç»Ÿå·¥å…·å±‚

from typing import Optional
import httpx
from crewai.tools import tool
from core.config import get_settings
from core.logging import get_logger
from crewai_tools import NL2SQLTool
from agent.tools.schema_tool import lookup_schema
from agent.tools.safe_sql_tool import execute_safe_sql
from agent.tools.safe_sql_guard import get_safe_sql_tool  # æ–°å¢:å®‰å…¨SQLå·¥å…·

logger = get_logger("tools")
settings = get_settings()


def get_sql_tool():
    """
    è·å–SQLæŸ¥è¯¢å·¥å…·(å¸¦å®‰å…¨æŠ¤æ )

    ä½¿ç”¨SafeSQLToolä»£æ›¿NL2SQLTool,å¢åŠ å®‰å…¨æ£€æŸ¥:
    - ç¦æ­¢ DROP/DELETE/UPDATE ç­‰ä¿®æ”¹æ“ä½œ
    - æ£€æŸ¥WHEREæ¡ä»¶é¿å…å…¨è¡¨æ‰«æ
    - é™åˆ¶è¿”å›ç»“æœæ•°é‡
    """
    return get_safe_sql_tool()


# ==================== RAG çŸ¥è¯†æ£€ç´¢å·¥å…· ====================


@tool("RAGçŸ¥è¯†æ£€ç´¢")
def query_knowledge(question: str) -> str:
    """
    ä» URGS çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

    Args:
        question: ç”¨æˆ·çš„é—®é¢˜æˆ–æŸ¥è¯¢å…³é”®è¯

    Returns:
        æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†å†…å®¹
    """
    settings = get_settings()
    rag_url = getattr(settings, "rag_service_url", "http://localhost:8001")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                f"{rag_url}/api/rag/query", json={"question": question}
            )
            response.raise_for_status()
            result = response.json()
            return result.get("answer", "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
    except httpx.HTTPError as e:
        logger.warning("rag_query_failed", error=str(e))
        return f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}"


@tool("æ–‡æ¡£æ‘˜è¦æ£€ç´¢")
def search_documents(keywords: str, top_k: int = 5) -> str:
    """
    æ ¹æ®å…³é”®è¯æœç´¢ç›¸å…³æ–‡æ¡£ã€‚

    Args:
        keywords: æœç´¢å…³é”®è¯
        top_k: è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5æ¡

    Returns:
        åŒ¹é…çš„æ–‡æ¡£åˆ—è¡¨æ‘˜è¦
    """
    settings = get_settings()
    rag_url = getattr(settings, "rag_service_url", "http://localhost:8001")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.post(
                f"{rag_url}/api/rag/search", json={"keywords": keywords, "top_k": top_k}
            )
            response.raise_for_status()
            result = response.json()
            docs = result.get("documents", [])
            if not docs:
                return "æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æ¡£"
            return "\n".join(
                [
                    f"- {doc.get('title', 'æ— æ ‡é¢˜')}: {doc.get('summary', '')}"
                    for doc in docs
                ]
            )
    except httpx.HTTPError as e:
        logger.warning("doc_search_failed", error=str(e))
        return f"æ–‡æ¡£æœç´¢å¤±è´¥: {str(e)}"


# ==================== SQL è¡€ç¼˜åˆ†æå·¥å…· ====================


@tool("SQLè¡€ç¼˜åˆ†æ")
def analyze_sql_lineage(sql: str, dialect: str = "mysql") -> str:
    """
    è§£æ SQL è¯­å¥ï¼Œåˆ†æè¡¨å’Œå­—æ®µçº§åˆ«çš„è¡€ç¼˜å…³ç³»ã€‚

    Args:
        sql: è¦åˆ†æçš„ SQL è¯­å¥
        dialect: SQL æ–¹è¨€ï¼Œæ”¯æŒ mysql, postgresql, hive ç­‰

    Returns:
        è¡€ç¼˜åˆ†æç»“æœï¼ŒåŒ…å«æºè¡¨ã€ç›®æ ‡è¡¨ã€å­—æ®µæ˜ å°„
    """
    settings = get_settings()
    lineage_url = getattr(settings, "lineage_service_url", "http://localhost:8002")

    try:
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                f"{lineage_url}/api/lineage/parse",
                json={"sql": sql, "dialect": dialect},
            )
            response.raise_for_status()
            result = response.json()

            # æ ¼å¼åŒ–è¡€ç¼˜ç»“æœ
            lineage = result.get("lineage", {})
            sources = lineage.get("sources", [])
            targets = lineage.get("targets", [])

            output = []
            output.append(f"**æºè¡¨**: {', '.join(sources) if sources else 'æ— '}")
            output.append(f"**ç›®æ ‡è¡¨**: {', '.join(targets) if targets else 'æ— '}")

            if "columns" in lineage:
                output.append("\n**å­—æ®µè¡€ç¼˜**:")
                for col in lineage["columns"]:
                    output.append(
                        f"  - {col.get('source', '?')} â†’ {col.get('target', '?')}"
                    )

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("lineage_analysis_failed", error=str(e))
        return f"è¡€ç¼˜åˆ†æå¤±è´¥: {str(e)}"


@tool("æŸ¥è¯¢è¡¨è¡€ç¼˜å…³ç³»")
def query_table_lineage(table_name: str, direction: str = "both") -> str:
    """
    æŸ¥è¯¢æŒ‡å®šè¡¨çš„è¡€ç¼˜å…³ç³»ï¼ˆä¸Šä¸‹æ¸¸ï¼‰ã€‚

    Args:
        table_name: è¡¨å
        direction: æŸ¥è¯¢æ–¹å‘ï¼Œupstream(ä¸Šæ¸¸)ã€downstream(ä¸‹æ¸¸)ã€both(åŒå‘)

    Returns:
        è¡¨çš„è¡€ç¼˜å…³ç³»å›¾
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(
                f"{api_url}/api/lineage/table/{table_name}",
                params={"direction": direction},
            )
            response.raise_for_status()
            result = response.json()

            upstream = result.get("upstream", [])
            downstream = result.get("downstream", [])

            output = [f"**è¡¨ {table_name} çš„è¡€ç¼˜å…³ç³»**"]
            if upstream:
                output.append(f"\nä¸Šæ¸¸è¡¨: {', '.join(upstream)}")
            if downstream:
                output.append(f"\nä¸‹æ¸¸è¡¨: {', '.join(downstream)}")
            if not upstream and not downstream:
                output.append("\næœªå‘ç°è¡€ç¼˜å…³ç³»")

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("table_lineage_query_failed", error=str(e))
        return f"è¡€ç¼˜æŸ¥è¯¢å¤±è´¥: {str(e)}"


# ==================== ä»»åŠ¡æ‰§è¡Œå·¥å…· ====================


@tool("æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨")
def list_jobs(status: Optional[str] = None, limit: int = 10) -> str:
    """
    æŸ¥è¯¢è°ƒåº¦ä»»åŠ¡åˆ—è¡¨ã€‚

    Args:
        status: ä»»åŠ¡çŠ¶æ€è¿‡æ»¤ï¼Œå¯é€‰å€¼ï¼šrunning, success, failed, pending
        limit: è¿”å›æ•°é‡é™åˆ¶

    Returns:
        ä»»åŠ¡åˆ—è¡¨ä¿¡æ¯
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        params = {"limit": limit}
        if status:
            params["status"] = status

        with httpx.Client(timeout=30.0) as client:
            response = client.get(f"{api_url}/api/jobs", params=params)
            response.raise_for_status()
            result = response.json()

            jobs = result.get("data", [])
            if not jobs:
                return "å½“å‰æ²¡æœ‰ä»»åŠ¡"

            output = ["**è°ƒåº¦ä»»åŠ¡åˆ—è¡¨**\n"]
            for job in jobs[:limit]:
                status_icon = {
                    "running": "ğŸ”„",
                    "success": "âœ…",
                    "failed": "âŒ",
                    "pending": "â³",
                }.get(job.get("status", ""), "â“")
                output.append(
                    f"{status_icon} [{job.get('id')}] {job.get('name', 'æœªå‘½å')} - {job.get('status', 'æœªçŸ¥')}"
                )

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("list_jobs_failed", error=str(e))
        return f"æŸ¥è¯¢ä»»åŠ¡å¤±è´¥: {str(e)}"


@tool("æŸ¥è¯¢ä»»åŠ¡è¯¦æƒ…")
def get_job_detail(job_id: str) -> str:
    """
    è·å–æŒ‡å®šä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ã€‚

    Args:
        job_id: ä»»åŠ¡ ID

    Returns:
        ä»»åŠ¡è¯¦æƒ…ï¼ŒåŒ…å«é…ç½®ã€æ‰§è¡Œå†å²ç­‰
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(f"{api_url}/api/jobs/{job_id}")
            response.raise_for_status()
            job = response.json().get("data", {})

            output = [
                f"**ä»»åŠ¡è¯¦æƒ…: {job.get('name', job_id)}**\n",
                f"- ID: {job.get('id')}",
                f"- çŠ¶æ€: {job.get('status')}",
                f"- ç±»å‹: {job.get('type', 'æœªçŸ¥')}",
                f"- Cron: {job.get('cron', 'æ— ')}",
                f"- æœ€åæ‰§è¡Œ: {job.get('lastRunTime', 'ä»æœªæ‰§è¡Œ')}",
            ]

            return "\n".join(output)
    except httpx.HTTPError as e:
        logger.warning("get_job_detail_failed", error=str(e))
        return f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}"


@tool("è§¦å‘ä»»åŠ¡æ‰§è¡Œ")
def trigger_job(job_id: str, params: Optional[str] = None) -> str:
    """
    è§¦å‘æŒ‡å®šä»»åŠ¡æ‰§è¡Œã€‚æ­¤æ“ä½œéœ€è¦å®¡æ‰¹ç¡®è®¤ã€‚

    Args:
        job_id: è¦æ‰§è¡Œçš„ä»»åŠ¡ ID
        params: å¯é€‰çš„æ‰§è¡Œå‚æ•° (JSON æ ¼å¼)

    Returns:
        æ‰§è¡Œè§¦å‘ç»“æœ

    æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªå†™æ“ä½œï¼Œç³»ç»Ÿå¯èƒ½ä¼šè¦æ±‚å®¡æ‰¹ç¡®è®¤ã€‚
    """
    settings = get_settings()
    api_url = getattr(settings, "api_service_url", "http://localhost:8080")

    try:
        import json

        body = {"jobId": job_id}
        if params:
            try:
                body["params"] = json.loads(params)
            except json.JSONDecodeError:
                body["params"] = params

        with httpx.Client(timeout=30.0) as client:
            response = client.post(f"{api_url}/api/jobs/{job_id}/trigger", json=body)
            response.raise_for_status()
            result = response.json()

            return f"âœ… ä»»åŠ¡ {job_id} å·²è§¦å‘æ‰§è¡Œï¼Œæ‰§è¡ŒID: {result.get('executionId', 'æœªçŸ¥')}"
    except httpx.HTTPError as e:
        logger.warning("trigger_job_failed", error=str(e))
        return f"è§¦å‘ä»»åŠ¡å¤±è´¥: {str(e)}"


# ==================== æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…· ====================


@tool("æ•°æ®è´¨é‡æ£€æŸ¥")
def check_data_quality(table_name: str) -> str:
    """
    æ£€æŸ¥æŒ‡å®šè¡¨çš„æ•°æ®è´¨é‡ï¼ŒåŒ…æ‹¬ NULL å€¼ç»Ÿè®¡ã€è¡Œæ•°ã€å¼‚å¸¸å€¼æ£€æµ‹ç­‰ã€‚

    Args:
        table_name: è¦æ£€æŸ¥çš„è¡¨å

    Returns:
        æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š
    """
    import pymysql

    try:
        conn = pymysql.connect(
            host=settings.db_host,
            port=settings.db_port,
            user=settings.db_user,
            password=settings.db_password,
            database=settings.db_name,
            charset="utf8mb4",
        )

        results = []
        with conn.cursor() as cursor:
            # 1. è·å–è¡Œæ•°
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            row_count = cursor.fetchone()[0]
            results.append(f"**æ€»è¡Œæ•°**: {row_count}")

            # 2. è·å–åˆ—ä¿¡æ¯
            cursor.execute(f"DESCRIBE {table_name}")
            columns = cursor.fetchall()
            results.append(f"**å­—æ®µæ•°**: {len(columns)}")

            # 3. æ£€æŸ¥æ¯åˆ—çš„ NULL å€¼
            null_stats = []
            for col in columns:
                col_name = col[0]
                cursor.execute(
                    f"SELECT COUNT(*) FROM {table_name} WHERE `{col_name}` IS NULL"
                )
                null_count = cursor.fetchone()[0]
                if null_count > 0:
                    null_rate = (null_count / row_count * 100) if row_count > 0 else 0
                    null_stats.append(
                        f"  - `{col_name}`: {null_count} ä¸ª NULL ({null_rate:.1f}%)"
                    )

            if null_stats:
                results.append("\n**NULL å€¼ç»Ÿè®¡**:")
                results.extend(null_stats)
            else:
                results.append("\n**NULL å€¼ç»Ÿè®¡**: æ—  NULL å€¼")

        conn.close()
        return "\n".join(results)

    except Exception as e:
        logger.warning("data_quality_check_failed", error=str(e))
        return f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {str(e)}"


# ==================== å·¥å…·é›†åˆ ====================


def get_rag_tools() -> list:
    """è·å– RAG ç›¸å…³å·¥å…·"""
    return [query_knowledge, search_documents]


def get_lineage_tools() -> list:
    """è·å–è¡€ç¼˜åˆ†æç›¸å…³å·¥å…·"""
    return [analyze_sql_lineage, query_table_lineage]


def get_executor_tools() -> list:
    """è·å–ä»»åŠ¡æ‰§è¡Œç›¸å…³å·¥å…·"""
    return [list_jobs, get_job_detail, trigger_job]


def get_data_quality_tools() -> list:
    """è·å–æ•°æ®è´¨é‡æ£€æŸ¥å·¥å…·"""
    return [check_data_quality, get_sql_tool()]


def get_banking_tools() -> list:
    """è·å–é“¶è¡Œç³»ç»Ÿå·¥å…·"""
    from agent.tools.banking_tools import (
        Search_1104_DB_Tool,
        Search_Core_DB_Tool,
        Search_EAST_DB_Tool,
        Search_YBT_DB_Tool,
    )

    return [
        Search_1104_DB_Tool(),
        Search_Core_DB_Tool(),
        Search_EAST_DB_Tool(),
        Search_YBT_DB_Tool(),
    ]


def get_all_tools() -> list:
    """è·å–æ‰€æœ‰å·¥å…·"""
    return (
        get_rag_tools()
        + get_lineage_tools()
        + get_executor_tools()
        + [check_data_quality]
        + get_banking_tools()
    )


def get_detective_tools() -> list:
    """è·å–æ•°æ®ä¾¦æ¢ä¸“ç”¨å·¥å…·"""
    return [lookup_schema, execute_safe_sql]
