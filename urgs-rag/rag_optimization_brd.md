# 全息 RAG 深度优化设计需求文档 (PRD)

## 1. 背景与目标
在数据量有限的情况下，传统 RAG 往往面临检索不精准（单薄片段）和回答缺乏深度的挑战。本项目旨在通过“全息数据增强”与“双路检索架构”，将有限的数据转化为具备逻辑深度的专业回答。

---

## 2. 核心技术架构

### 2.1 数据层：全息片段处理 (Holographic Enrichment)
**目标**：将单薄的知识片段转变为包含多维信息的 Rich Object。
- **QA 自动化生成**：对每段入库知识，利用 LLM 预生成 5-10 个模拟用户问题。
- **逻辑核提取 (Reasoning Kernel)**：分析该知识背后的“为什么”和“怎么做”，提炼操作逻辑。
- **场景场景化标签**：根据文本内容自动标注业务场景、用户情绪或适用阶段。

### 2.2 索引层：双路向量路由 (Dual-Path Indexing)
**目标**：分离“事实”与“逻辑”，提升检索命中率。
- **语义路 (Semantic Path)**：存储原始知识文本片段，负责解决“是什么”的直接搜索。
- **逻辑路 (Logic Path)**：存储模拟 QA 和逻辑核，负责意图匹配与逻辑对齐。
- **父子文档架构 (Parent-Child)**：库内检索更细粒度的 Child 块，回答时召回更丰满的 Parent 上下文。

### 2.3 召回层：混合检索与权重融合 (Hybrid Recall)
**目标**：结合关键词精度与向量语义广度。
- **三路混合检索**：`BM25 (关键词)` + `语义路向量` + `逻辑路向量`。
- **动态权重管理**：通过集成检索器 (EnsembleRetriever) 对三路结果进行 RRF 排名重排，增强对专有名词的锁定能力。

---

## 3. 功能设计

### 3.1 增强问答工作流 (Enhanced QA Workflow)
1. **意图解析**：用户提问接入。
2. **多路并行检索**：同时检索语义路、逻辑路和关键词索引。
3. **CoT 模板注入 (Thinking Chain)**：
   - 拼装结构：`【已知事实】 + 【思考范式】 + 【场景标签】 + 【任务指令】`。
4. **LLM 推导生成**：强制模型参考“逻辑核”进行思维推演，而非简单的文字拼接。

### 3.2 治理与统计集成
- **Token 消耗闭环**：全流程（包含入库时的 LLM 增强和问答时的 LLM 生成）均通过后端 API 管理接口记录 Token 统计。
- **API 动态同步**：RAG 模块动态跟随系统的默认 API 设置，实现配置集中化。

---

## 4. 接口规范

### 4.1 增强问答服务
- **Endpoint**: `POST /api/rag/query`
- **输入**: `query` (用户问题), `k` (检索深度)
- **输出**: 
  - `answer`: 经过思维链增强的专业回答。
  - `results`: 溯源文档列表。
  - `tags`: 系统识别到的业务场景标签。

---

## 5. 预期价值
- **检索准确率提升**：由于逻辑核和 QA 的存在，大幅降低“词不达意”导致的检索失败。
- **回答深度提升**：回答中包含明显的逻辑推演过程，更具专家感。
- **维护成本降低**：利用 LLM 自动处理原始文档，减轻人工标注负担。